{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import collections \n",
    "import spacy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import unidecode\n",
    "import concurrent.futures\n",
    "import tensorflow as tf\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142568, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "\n",
    "filename = \"../full_articles.csv\"\n",
    "filepath = os.path.join(os.getcwd(), filename)\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "data.dropna(how=\"any\", subset=[\"title\", \"content\", \"publication\"], inplace=True)\n",
    "\n",
    "SAVE_DIR = \"pickles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data.publication.apply(lambda x: x == \"NPR\")]\n",
    "contents = data.content.tolist()\n",
    "contents = [unidecode.unidecode(content).lower() for content in contents]\n",
    "# delete the unneeded data\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done tokenizing...\n"
     ]
    }
   ],
   "source": [
    "def process_content(contents_data, sequence_length=128, batch_size=128, decode_unicode=False):\n",
    "    if decode_unicode:\n",
    "        contents_data = [unidecode.unidecode(content).lower() for content in contents]\n",
    "    else:\n",
    "        contents_data = [content.lower() for content in contents]\n",
    "\n",
    "    tokenized = [[word.text for word in doc] for doc in nlp.pipe(contents_data, batch_size=128)]\n",
    "    print(\"done tokenizing...\")\n",
    "    words_dict = collections.Counter([word for doc in tokenized for word in doc])\n",
    "    words = list(sorted([word[0] for word in words_dict.most_common()]))\n",
    "    words_dict = {x: i for i,x in enumerate(words)}\n",
    "    contents_translated = [[words_dict[word] for word in doc] for doc in tokenized]\n",
    "    \n",
    "    batch_chunks = []\n",
    "    for doc in contents_translated:\n",
    "        batch_chunks_item = [doc[i:i+sequence_length+batch_size] for i in range(0, len(doc) - batch_size, batch_size)]\n",
    "        batch_chunks.extend(batch_chunks_item)\n",
    "    \n",
    "    return batch_chunks, words_dict, words\n",
    "\n",
    "content_batches, content_words_dict, content_words = process_content(contents)\n",
    "# save translators\n",
    "name = \"content_word_rnn\"\n",
    "PKL_SAVE = f\"{name}.pkl\"\n",
    "with open(os.path.join(\"pickles\",PKL_SAVE), \"wb\") as pkl_file:\n",
    "    pickle.dump((content_batches, content_words_dict, content_words), pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"content_word_rnn\"\n",
    "PKL_SAVE = f\"{name}.pkl\"\n",
    "with open(os.path.join(\"pickles\",PKL_SAVE), \"rb\") as pkl_file:\n",
    "    content_batches, content_words_dict, content_words = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to HDF5 file for dynamic loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "seq_length = 128\n",
    "f = h5py.File(\"rnn_data\", \"w\")\n",
    "predictor_grp = f.create_group(\"batches\")\n",
    "for i,batch in enumerate(content_batches):\n",
    "    predictor_grp.create_dataset(name=f\"batch{i}\", shape=(len(batch),), data=np.array(batch))\n",
    "f.create_dataset(\"max_batch\", shape=(1,), data=np.array([i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class WordRNNSequence(Sequence):\n",
    "    def __init__(self, batch_idx, batch_data, seq_length, n_vocab, validation=False, training_sequence=None):\n",
    "        self.batch_idx = batch_idx\n",
    "        self.batch_data = batch_data\n",
    "        self.seq_length = seq_length\n",
    "        self.n_vocab = n_vocab\n",
    "        if validation and not training_sequence:\n",
    "            raise FileNotFoundError(\"need non-null training keras.utils.Sequence\")\n",
    "        if validation:\n",
    "            assert isinstance(training_sequence, Sequence)\n",
    "            self.training_sequence = training_sequence\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batch_idx)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        data = self.batch_data[f\"batch{key}\"][:]\n",
    "        len_batch = data.shape[0] - self.seq_length\n",
    "        batch_x = np.zeros((len_batch, self.seq_length, self.n_vocab), dtype=np.bool)\n",
    "        for i in range(0, len_batch):\n",
    "            seq = data[i:i+self.seq_length]\n",
    "            batch_x[i,] = to_categorical(seq, num_classes=self.n_vocab)\n",
    "        batch_y = data[self.seq_length:]\n",
    "        batch_y = to_categorical(batch_y, num_classes=self.n_vocab)\n",
    "        batch_y = batch_y.astype(np.bool)\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.validation:\n",
    "            all_batch_idx = self.batch_idx + self.training_sequence.batch_idx\n",
    "            self.training_sequence.batch_idx, self.batch_idx = train_test_split(all_batch_idx, test_size=0.2)\n",
    "               \n",
    "    def _batch_len(self, true_idx):\n",
    "        data = self.batch_data[true_idx]\n",
    "        len_batch = len(data) - int(self.seq_length)\n",
    "        return len_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "def encode_sequences(sequences, word_dict, seq_length, n_vocab):\n",
    "    data = np.zeros(shape=(len(sequences), seq_length, n_vocab), dtype=np.bool) # extra word for OOV words \n",
    "    for i,sequence in enumerate(sequences): \n",
    "        if len(sequence) > seq_length:\n",
    "            sequence = sequence[:seq_length]\n",
    "        elif len(sequence) < seq_length:\n",
    "            raise NotImplementedError(f\"Need a sequence of length {seq_length}\")\n",
    "        for j,word in enumerate(sequence):\n",
    "            word_lower = word.lower()\n",
    "            if word_lower in word_dict:\n",
    "                data[i, j, word_dict[word_lower]] = 1\n",
    "            else:\n",
    "                data[i, j, n_vocab - 1] = 1\n",
    "\n",
    "    return(data)\n",
    "\n",
    "def encode_next_words(next_words, word_dict, n_vocab):\n",
    "    next_word_encode = np.zeros(shape=(len(next_words), n_vocab), dtype=np.bool) # extra word for OOV words \n",
    "    for i,next_word in enumerate(next_words):\n",
    "        next_word_lower = next_word.lower()\n",
    "        if next_word_lower in word_dict:\n",
    "            next_word_encode[i, word_dict[next_word_lower]] = 1\n",
    "        else:\n",
    "            next_word_encode[i, n_vocab - 1] = 1\n",
    "            \n",
    "    return(next_word_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [97103,2048] and type float\n\t [[{{node training_1/Adam/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [97103,2048] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training_1/Adam/zeros', defined at:\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-096a55f38af7>\", line 62, in <module>\n    max_queue_size=1)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\", line 1415, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training_generator.py\", line 39, in fit_generator\n    model._make_train_function()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\", line 498, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 700, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2817, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3254, in create_op\n    op_def=op_def)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1750, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [97103,2048] and type float\n\t [[{{node training_1/Adam/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [97103,2048] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [97103,2048] and type float\n\t [[{{node training_1/Adam/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [97103,2048] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-096a55f38af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                    max_queue_size=1)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_CHECK_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_gen_title.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [97103,2048] and type float\n\t [[{{node training_1/Adam/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [97103,2048] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'training_1/Adam/zeros', defined at:\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-096a55f38af7>\", line 62, in <module>\n    max_queue_size=1)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\", line 1415, in fit_generator\n    initial_epoch=initial_epoch)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training_generator.py\", line 39, in fit_generator\n    model._make_train_function()\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/engine/training.py\", line 498, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/optimizers.py\", line 482, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 700, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2817, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3254, in create_op\n    op_def=op_def)\n  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1750, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [97103,2048] and type float\n\t [[{{node training_1/Adam/zeros}} = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [97103,2048] values: [0 0 0...]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Bidirectional, LSTM, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "\n",
    "\n",
    "n_nodes = 512\n",
    "#class WordRNNSequence(Sequence):\n",
    "#    def __init__(self, batch_idx, batch_data, seq_length, n_vocab, validation=False):\n",
    "#    content_batches, content_words_dict, content_words = pickle.load(pkl_file)\n",
    "f = h5py.File(\"rnn_data\", \"r\")\n",
    "num_batches = f[\"max_batch\"][0]\n",
    "train_idx, validation_idx = train_test_split(np.arange(num_batches), test_size=0.2)\n",
    "\n",
    "hdf5_batch_data = f[\"batches\"]\n",
    "\n",
    "train = {\n",
    "    \"batch_idx\": train_idx, \n",
    "    \"batch_data\": hdf5_batch_data, \n",
    "    \"seq_length\": 128, \n",
    "    \"n_vocab\": len(content_words)\n",
    "}\n",
    "\n",
    "valid = {\n",
    "    \"batch_idx\": validation_idx, \n",
    "    \"batch_data\": hdf5_batch_data, \n",
    "    \"seq_length\": 128, \n",
    "    \"n_vocab\": len(content_words)\n",
    "}\n",
    "\n",
    "train_sequence = WordRNNSequence(**train)\n",
    "valid_sequence = WordRNNSequence(training_sequence=train_sequence, **valid)\n",
    "\n",
    "\n",
    "SEQ_LENGTH = 128\n",
    "N_VOCAB = len(content_words)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(n_nodes, activation=\"relu\"), input_shape = (SEQ_LENGTH, N_VOCAB)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(N_VOCAB))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "callbacks = [EarlyStopping(patience=2, monitor=\"val_loss\")]\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[categorical_accuracy])\n",
    "MODEL_CHECK_DIR = \"checkpoints\"\n",
    "callbacks=[EarlyStopping(patience=4, monitor='val_loss'),\n",
    "           ModelCheckpoint(filepath='model_gen.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                           monitor='val_loss',\n",
    "                           verbose=0, mode='auto',\n",
    "                           period=2)]\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "model.fit_generator(train_sequence,\n",
    "                    epochs = epochs,\n",
    "                    validation_data=valid_sequence,\n",
    "                    callbacks=callbacks,\n",
    "                   max_queue_size=1)\n",
    "\n",
    "model.save(os.path.join(os.getcwd(), MODEL_CHECK_DIR, 'model_gen_title.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"rnn_data\" (mode r)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    t = np.asarray(preds).astype(np.float64)\n",
    "    t = np.log(t) / temperature\n",
    "    t = np.exp(t)\n",
    "    t = t / np.sum(t)\n",
    "    probs = np.random.multinomial(1, t, 1)\n",
    "    return np.argmax(probs)\n",
    "\n",
    "def gen_words(model, seed, word_num, word_dict, seq_length, words_index, temperature=1.0):\n",
    "    \"\"\"`nlp` must be defined\"\"\"\n",
    "    words = [word.text for word in nlp(seed) if word.is_alpha or word.is_punct]\n",
    "    \n",
    "    generated = words\n",
    "\n",
    "\n",
    "    for i in range(word_num):\n",
    "        encoded = encode_sequence(words, word_dict, seq_length)\n",
    "        preds = model.predict(encoded)[0]\n",
    "        result = sample(preds, temperature)\n",
    "        next_word = words_index[result]\n",
    "        generated.append(next_word)\n",
    "        words = words[1:] + [next_word]\n",
    "        \n",
    "    return \" \".join(generated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'breaking news : trump announced a speech in which he denounced has called seen been to in to his his the life life presidency because , , a many there notes likely never many on a small more baby group than than , the any right tv professor , . , ” ” but i i it know have , in to i a my like very mind album , , . i i you think am know that is that the the this way national administration is company . often in has only all a creating over familiar ways all , the the ” national small and war source people in of to the the make new community line business , . at but but least all there years of are , trump more though in than , another a putin parents year more would . to take ” remember the a any ” museum genome video director . . . ” but .. they they the were say same , in plan ” which that to is happens be still to the . repeal move ” of in : that obamacare you people and can would no find follow follow why her , would of pontzer have things to'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_words(model=model, seed=\"breaking news: trump announced a speech in which he denounced\",\n",
    "          word_num=200,\n",
    "          word_dict=content_word_dict,\n",
    "          seq_length=10,\n",
    "          words_index=content_vocab,\n",
    "         temperature=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
